{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 출력층 설계 (Output layer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: torch in c:\\users\\hyuna\\anaconda3\\envs\\pystudy_env\\lib\\site-packages (2.6.0+cu118)\n",
      "Requirement already satisfied: torchvision in c:\\users\\hyuna\\anaconda3\\envs\\pystudy_env\\lib\\site-packages (0.21.0+cu118)\n",
      "Requirement already satisfied: torchaudio in c:\\users\\hyuna\\anaconda3\\envs\\pystudy_env\\lib\\site-packages (2.6.0+cu118)\n",
      "Requirement already satisfied: filelock in c:\\users\\hyuna\\anaconda3\\envs\\pystudy_env\\lib\\site-packages (from torch) (3.13.1)\n",
      "Requirement already satisfied: typing-extensions>=4.10.0 in c:\\users\\hyuna\\anaconda3\\envs\\pystudy_env\\lib\\site-packages (from torch) (4.13.1)\n",
      "Requirement already satisfied: networkx in c:\\users\\hyuna\\anaconda3\\envs\\pystudy_env\\lib\\site-packages (from torch) (3.4.2)\n",
      "Requirement already satisfied: jinja2 in c:\\users\\hyuna\\anaconda3\\envs\\pystudy_env\\lib\\site-packages (from torch) (3.1.6)\n",
      "Requirement already satisfied: fsspec in c:\\users\\hyuna\\anaconda3\\envs\\pystudy_env\\lib\\site-packages (from torch) (2024.6.1)\n",
      "Requirement already satisfied: setuptools in c:\\users\\hyuna\\anaconda3\\envs\\pystudy_env\\lib\\site-packages (from torch) (75.8.0)\n",
      "Requirement already satisfied: sympy==1.13.1 in c:\\users\\hyuna\\anaconda3\\envs\\pystudy_env\\lib\\site-packages (from torch) (1.13.1)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in c:\\users\\hyuna\\anaconda3\\envs\\pystudy_env\\lib\\site-packages (from sympy==1.13.1->torch) (1.3.0)\n",
      "Requirement already satisfied: numpy in c:\\users\\hyuna\\anaconda3\\envs\\pystudy_env\\lib\\site-packages (from torchvision) (2.2.4)\n",
      "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in c:\\users\\hyuna\\anaconda3\\envs\\pystudy_env\\lib\\site-packages (from torchvision) (11.0.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\hyuna\\anaconda3\\envs\\pystudy_env\\lib\\site-packages (from jinja2->torch) (3.0.2)\n"
     ]
    }
   ],
   "source": [
    "!pip3 install torch torchvision torchaudio"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 소프트맥스 오버플로우 방지"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- ✅ 오버플로우(Overflow)란?\n",
    "- 컴퓨터가 다룰 수 있는 수의 범위를 넘어서 버리는 현상\n",
    "- 🧠 쉽게 말하면:\n",
    "- 너무 너무 큰 숫자를 계산하려다가 컴퓨터가 \"못해!\" 하고 터지는 것"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- ✅ 먼저 Softmax란?\n",
    "- 벡터 값을 확률 분포처럼 바꿔주는 함수야.\n",
    "- 각 값을 지수(exp)로 바꾸고, 전체 합으로 나눠서 합이 1이 되도록 정규화함."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[nan nan nan]\n",
      "[0.09003057 0.24472847 0.66524096]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\hyuna\\AppData\\Local\\Temp\\ipykernel_17548\\3860681584.py:4: RuntimeWarning: overflow encountered in exp\n",
      "  exp_x = np.exp(x)\n",
      "C:\\Users\\hyuna\\AppData\\Local\\Temp\\ipykernel_17548\\3860681584.py:5: RuntimeWarning: invalid value encountered in divide\n",
      "  return exp_x / np.sum(exp_x)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "def softmax(x):\n",
    "    exp_x = np.exp(x)\n",
    "    return exp_x / np.sum(exp_x)\n",
    "\n",
    "def stable_softmax(x):\n",
    "    exp_x = np.exp(x - np.max(x))\n",
    "    return exp_x / np.sum(exp_x)\n",
    "\n",
    "\n",
    "x = np.array([1000, 1001, 1002])\n",
    "\n",
    "print(softmax(x))\n",
    "print(stable_softmax(x))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- ✅ 왜 - np.max(x) 하는 거야?\n",
    "- 수학적으로는 결과에 영향을 안 줘\n",
    "- 왜냐하면 softmax는 어차피 이렇게 계산되니까:\n",
    "\n",
    "$$\n",
    "\\text{softmax}(x_i) = \\frac{e^{x_i}}{\\sum_j e^{x_j}} = \\frac{e^{x_i - C}}{\\sum_j e^{x_j - C}}\n",
    "$$\n",
    "\n",
    "- 👉 어떤 값을 전체에서 같이 빼도 결과는 같아\n",
    "- 그래서 np.max(x)를 빼서 계산을 안정화(overflow 방지) 하는 거야!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- PyTorch 라이브러리 함수 사용"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0.0900, 0.2447, 0.6652])\n",
      "tensor([1., 1., 1.])\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn.functional as F\n",
    "\n",
    "x = torch.tensor([1000, 1001, 1002], dtype=torch.float32)\n",
    "\n",
    "softmax_output = F.softmax(x, dim=0)    # dim: softmax를 적용할 축\n",
    "print(softmax_output)\n",
    "\n",
    "sigmoid_output = torch.sigmoid(x)\n",
    "print(sigmoid_output)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 손실 함수와 연계"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 신경망 생성\n",
    "# torch.nn 패키지 사용\n",
    "# nn.Module을 상속받고, 해당 모듈은 계층과 output을 반환하는 forward메소드를 포함\n",
    "# 파이토치에서 신경망생성을 위한 기본 틀\n",
    "# 1. class Net(nn.Module):\n",
    "\n",
    "#     def __init__(self):\n",
    "#         super(Net, self).__init__()\n",
    "\n",
    "# 2. class MyModel(nn.Module):\n",
    "\n",
    "#     def __init__(self):\n",
    "#         super(MyModel, self).__init__()\n",
    "# conv2d 에이어를 쌓을 때, 필터의 갯수를 계산하고 in_channels에 넣어줘야함"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.1807864904403687\n",
      "1.1498682498931885\n",
      "1.1196541786193848\n",
      "1.0901648998260498\n",
      "1.0614186525344849\n",
      "1.0334306955337524\n",
      "1.0062131881713867\n",
      "0.9797751307487488\n",
      "0.9541224241256714\n",
      "0.929257333278656\n"
     ]
    }
   ],
   "source": [
    "# \"순전파 → 손실 계산 → 역전파 → 가중치 업데이트\"\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "\n",
    "# 간단한 다중 클래스 분류 모델 정의 (입력 값: 5개, 출력: 3 클래스)\n",
    "class SimpleMultiClassModel(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(SimpleMultiClassModel, self).__init__()\n",
    "        self.fc = nn.Linear(5, 3) # 입력 5개 → 출력 3개 (클래스 수), (즉, 클래스 3개 예측측)\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.fc(x)\n",
    "    \n",
    "model = SimpleMultiClassModel()\n",
    "criterion = nn.CrossEntropyLoss() # → softmax + log + loss 계산까지 다 포함된 손실 함수, → 출력값은 softmax 안 써도 됨!!\n",
    "# nn.CrossEntropyLoss()는 내부적으로 이렇게 계산함:log_softmax(output) + NLLLoss, → softmax 따로 쓰면 오히려 안 좋음 (중복됨)\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.01) # → 학습을 위한 가중치 최적화 알고리즘\n",
    "\n",
    "# 데이터 생성\n",
    "inputs = torch.randn(4, 5) # 샘플 4개, 각 샘플은 5개의 입력 특성\n",
    "labels = torch.tensor([0, 2, 1, 0]) # 각 샘플의 정답 클래스 (정수로 표현)\n",
    "\n",
    "for _ in range(10):\n",
    "    preds = model(inputs)           # 순전파\n",
    "    loss = criterion(preds, labels) # 손실 계산\n",
    "    print(loss.item())\n",
    "\n",
    "    optimizer.zero_grad()   # 이전 단계에서 계산된 기울기를 0으로 초기화\n",
    "    loss.backward()         # 손실에 대한 역전파 수행 (파라미터에 대한 기울기 계산)\n",
    "    optimizer.step()        # 계산된 기울기를 사용하여 옵티마이저가 모델의 파라미터 업데이트"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pystudy_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
