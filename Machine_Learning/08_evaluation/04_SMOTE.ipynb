{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SMOTE 적용\n",
    "### SMOTE 란?\n",
    "- SMOTE는 Synthetic Minority Over-sampling Technique의 줄임말이에요.\n",
    "- 한국말로 하면 \"소수 클래스에 대해 가짜 데이터를 만들어서 데이터 균형을 맞추는 기법\" 입니다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 왜 필요한가?\n",
    "- 클래스(0)(정상) - 900개\n",
    "- 클래스(1)(이상) - 100개\n",
    "- 이런 식으로 데이터가 한쪽으로 쏠려 있는 경우, 모델이 제대로 학습되지 않아요. 왜냐면…\n",
    "- 모델이 \"클래스 0만 예측해도 정확도가 90%\"가 되기 때문이에요 \n",
    "- 하지만 정작 중요한 건 클래스 1(이상)을 잘 잡아내는 거잖아요?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 그래서 등장한 게 SMOTE!\n",
    "- SMOTE는 소수 클래스의 데이터를 복제하는 게 아니라\n",
    "- 👉 **기존 소수 클래스 데이터를 바탕으로 비슷하지만 새로운 데이터를 \"생성\"**합니다.\n",
    "\n",
    "- 🧬 어떻게 생성하나요? (아주 간단한 설명)\n",
    "- 소수 클래스 데이터 하나를 고릅니다.\n",
    "\n",
    "- 그와 가까운 다른 소수 클래스 데이터들을 찾습니다. (보통 K=5 기준으로)\n",
    "\n",
    "- 이웃들과 선을 그어서 그 선 위에 중간 지점을 랜덤하게 뽑아 새로운 데이터를 생성합니다.\n",
    "\n",
    "\n",
    "- 원래 있던 점(●)과 이웃 사이를 선으로 연결해\n",
    "- 그 사이 어딘가에 새로운 점(★)을 만든다고 보면 돼요!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 소수 클래스의 데이터를 늘려 데이터 불균형 문제 해결, 기존 소수 클래스 데이터를 기반으로 새로운 데이터 생성, 데이터 복제 대신 생성     → 과적합 줄이고 학습 성능 향상"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting imbalanced-learn\n",
      "  Downloading imbalanced_learn-0.13.0-py3-none-any.whl.metadata (8.8 kB)\n",
      "Requirement already satisfied: numpy<3,>=1.24.3 in c:\\users\\hyuna\\anaconda3\\envs\\pystudy_env\\lib\\site-packages (from imbalanced-learn) (2.2.4)\n",
      "Requirement already satisfied: scipy<2,>=1.10.1 in c:\\users\\hyuna\\anaconda3\\envs\\pystudy_env\\lib\\site-packages (from imbalanced-learn) (1.15.2)\n",
      "Requirement already satisfied: scikit-learn<2,>=1.3.2 in c:\\users\\hyuna\\anaconda3\\envs\\pystudy_env\\lib\\site-packages (from imbalanced-learn) (1.6.1)\n",
      "Collecting sklearn-compat<1,>=0.1 (from imbalanced-learn)\n",
      "  Downloading sklearn_compat-0.1.3-py3-none-any.whl.metadata (18 kB)\n",
      "Requirement already satisfied: joblib<2,>=1.1.1 in c:\\users\\hyuna\\anaconda3\\envs\\pystudy_env\\lib\\site-packages (from imbalanced-learn) (1.4.2)\n",
      "Requirement already satisfied: threadpoolctl<4,>=2.0.0 in c:\\users\\hyuna\\anaconda3\\envs\\pystudy_env\\lib\\site-packages (from imbalanced-learn) (3.6.0)\n",
      "Downloading imbalanced_learn-0.13.0-py3-none-any.whl (238 kB)\n",
      "Downloading sklearn_compat-0.1.3-py3-none-any.whl (18 kB)\n",
      "Installing collected packages: sklearn-compat, imbalanced-learn\n",
      "Successfully installed imbalanced-learn-0.13.0 sklearn-compat-0.1.3\n"
     ]
    }
   ],
   "source": [
    "!pip install imbalanced-learn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### **📌 `imblearn` (imbalanced-learn) 패키지**\n",
    "**주요 기능**\n",
    "1. **오버샘플링(Over-sampling)** → 소수 클래스 데이터 샘플을 증가시킴  \n",
    "   - `SMOTE` (Synthetic Minority Over-sampling Technique)  \n",
    "   - `ADASYN` (Adaptive Synthetic Sampling)  \n",
    "\n",
    "2. **언더샘플링(Under-sampling)** → 다수 클래스 데이터 샘플을 줄임  \n",
    "   - `RandomUnderSampler`  \n",
    "   - `NearMiss`  \n",
    "\n",
    "3. **앙상블 기법(Ensemble Methods)**  \n",
    "   - `BalancedBaggingClassifier` → 클래스 균형을 유지하며 배깅 적용  \n",
    "   - `BalancedRandomForestClassifier` → 불균형 데이터에 최적화된 랜덤 포레스트  \n",
    "\n",
    "4. **SMOTE 변형 기법**  \n",
    "   - `BorderlineSMOTE` → 경계선 샘플만 증강  \n",
    "   - `SMOTENC` → 범주형 데이터를 포함한 SMOTE "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 언더샘플링은 다수 클래스(너무 많은 클래스)의 데이터를 일부만 남기고 버리는 방법. \n",
    "- 다수 클래스 데이터가 너무 많을 때 (모델이 너무 많은 정상 데이터를 학습하면, **소수 클래스(예: 이상 탐지)**를 무시할 수 있음.)\n",
    "- 데이터 전체량이 너무 커서 학습 시간이 오래 걸릴 때 (일부만 써도 충분히 패턴을 배울 수 있다면 효율적!)\n",
    "- 소수 클래스 데이터를 늘리기 어려울 때 (SMOTE로 새로운 데이터를 만들기 힘든 상황에서 차선책으로 사용.)\n",
    "\n",
    "- 언더샘플링 할때 주의할 점은, 데이터를 줄이기 때문에 중요한 정보가 손실될 수 있어요. → 그래서 너무 과하게 줄이면 모델 성능이 오히려 나빠질 수 있어요."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 두개 섞어서 쓰는 방법도 있음\n",
    "- 소수 클래스는 오버샘플링, 다수 클래스는 약간만 언더샘플링 해서 균형도 맞추고, 성능도 챙기는 전략.\n",
    "\n",
    "- from imblearn.combine import SMOTEENN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Before SMOTE: [897 103]\n",
      "After SMOTE: [897 897]\n",
      "(1000, 20) (1000,)\n",
      "(1794, 20) (1794,)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\hyuna\\anaconda3\\envs\\pystudy_env\\Lib\\site-packages\\joblib\\externals\\loky\\backend\\context.py:136: UserWarning: Could not find the number of physical cores for the following reason:\n",
      "[WinError 2] 지정된 파일을 찾을 수 없습니다\n",
      "Returning the number of logical cores instead. You can silence this warning by setting LOKY_MAX_CPU_COUNT to the number of cores you want to use.\n",
      "  warnings.warn(\n",
      "  File \"c:\\Users\\hyuna\\anaconda3\\envs\\pystudy_env\\Lib\\site-packages\\joblib\\externals\\loky\\backend\\context.py\", line 257, in _count_physical_cores\n",
      "    cpu_info = subprocess.run(\n",
      "               ^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\hyuna\\anaconda3\\envs\\pystudy_env\\Lib\\subprocess.py\", line 550, in run\n",
      "    with Popen(*popenargs, **kwargs) as process:\n",
      "         ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\hyuna\\anaconda3\\envs\\pystudy_env\\Lib\\subprocess.py\", line 1028, in __init__\n",
      "    self._execute_child(args, executable, preexec_fn, close_fds,\n",
      "  File \"c:\\Users\\hyuna\\anaconda3\\envs\\pystudy_env\\Lib\\subprocess.py\", line 1540, in _execute_child\n",
      "    hp, ht, pid, tid = _winapi.CreateProcess(executable, args,\n",
      "                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n"
     ]
    }
   ],
   "source": [
    "# SMOTE를 이용해서 불균형한 데이터셋을 균형 있게 바꾸는 과정\n",
    "import numpy as np\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from sklearn.datasets import make_classification\n",
    "\n",
    "X, y = make_classification( # make_classification: 머신러닝 테스트용 데이터를 만들어주는 함수\n",
    "    n_classes=2, # 두 개의 클래스로 분류 (예: 정상/이상)\n",
    "    weights=[0.9, 0.1], # 클래스 0: 90%, 클래스 1: 10% \n",
    "    n_samples=1000, # 총 1000개 샘플 생성\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "print(f\"Before SMOTE: {np.bincount(y)}\") # np.bincount(y)는 클래스별 샘플 개수를 세어줘요\n",
    "\n",
    "smote = SMOTE(random_state=42) # SMOTE()를 사용해서 소수 클래스(클래스 1)의 데이터를 인공적으로 \"생성\"\n",
    "X_resample, y_resample = smote.fit_resample(X, y) # it_resample(X, y)를 통해 새로운 balanced 데이터셋을 얻어요\n",
    "\n",
    "print(f\"After SMOTE: {np.bincount(y_resample)}\")\n",
    "print(X.shape, y.shape)\n",
    "print(X_resample.shape, y_resample.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.98      0.98       179\n",
      "           1       0.85      0.81      0.83        21\n",
      "\n",
      "    accuracy                           0.96       200\n",
      "   macro avg       0.91      0.90      0.90       200\n",
      "weighted avg       0.96      0.96      0.96       200\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "X_train, X_test, y_train, y_test = \\\n",
    "    train_test_split(X, y, test_size=0.2, stratify=y) \n",
    "# test_size=0.2: 테스트 데이터는 전체의 20%, stratify=y: 클래스 비율이 학습/테스트에 동일하게 유지되도록 함 (불균형 데이터일 때 중요!)\n",
    "\n",
    "model = RandomForestClassifier(random_state=0) # RandomForestClassifier: 여러 개의 결정 트리를 조합한 앙상블 모델 \n",
    "model.fit(X_train, y_train) # .fit(): 학습 데이터를 이용해 모델 훈련\n",
    "\n",
    "y_pred = model.predict(X_test)\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Precision 은 내가 1이라고 예측한 것 중에 진짜 1인 비율\n",
    "- recall 은 실제 1 중에서 내가 맞춘 비율\n",
    "- f1-score 는 precision과 recall의 균형\n",
    "- support 는 각 클래스의 샘플 수\n",
    "- accuracy 는 전체 샘플 중 맞춘 비율\n",
    "- marco avg 는 클래스마다 계산한 평균 (모든 클래스 동등하게 반영)\n",
    "- weighted avg 클래스 개수 비율을 가중치로 반영한 평균\n",
    "\n",
    "- 🎯 F1-score가 필요한 이유?\n",
    "- Precision이 높아도 Recall이 낮으면? → 놓치는 케이스 많음\n",
    "\n",
    "- Recall이 높아도 Precision이 낮으면? → 잘못된 경고가 많음\n",
    "- ➡️ 이럴 때, 두 값을 적절히 균형 있게 평가하는 게 F1-score!\n",
    "- 🧠 왜 **조화 평균(Harmonic Mean)**을 쓰나요?\n",
    "- 단순 평균(mean)은 큰 값이 작음을 보완해버리지만,\n",
    "\n",
    "- 조화 평균은 작은 값에 더 민감해서,\n",
    "- Precision이나 Recall 둘 중 하나라도 낮으면 F1도 낮게 나와요!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.95      0.96       181\n",
      "           1       0.95      0.98      0.96       178\n",
      "\n",
      "    accuracy                           0.96       359\n",
      "   macro avg       0.96      0.96      0.96       359\n",
      "weighted avg       0.96      0.96      0.96       359\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# \"SMOTE로 늘린 데이터(X_resample, y_resample)를 훈련/테스트용으로 나눈 다음,\n",
    "# 랜덤 포레스트로 학습 → 예측 → 성능 평가(classification_report)까지 쭉 실행하는 코드\"\n",
    "\n",
    "X_train, X_test, y_train, y_test = \\\n",
    "    train_test_split(X_resample, y_resample, test_size=0.2) #X_resample, y_resample: SMOTE로 클래스 균형을 맞춘 데이터\n",
    "\n",
    "model = RandomForestClassifier(random_state=0)\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "y_pred = model.predict(X_test)\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 코드에서 \\ 는 코드간의 띄어쓰기 용도"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pystudy_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
