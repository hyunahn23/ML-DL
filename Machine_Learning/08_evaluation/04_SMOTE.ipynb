{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SMOTE ì ìš©\n",
    "### SMOTE ë€?\n",
    "- SMOTEëŠ” Synthetic Minority Over-sampling Techniqueì˜ ì¤„ì„ë§ì´ì—ìš”.\n",
    "- í•œêµ­ë§ë¡œ í•˜ë©´ \"ì†Œìˆ˜ í´ë˜ìŠ¤ì— ëŒ€í•´ ê°€ì§œ ë°ì´í„°ë¥¼ ë§Œë“¤ì–´ì„œ ë°ì´í„° ê· í˜•ì„ ë§ì¶”ëŠ” ê¸°ë²•\" ì…ë‹ˆë‹¤."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ì™œ í•„ìš”í•œê°€?\n",
    "- í´ë˜ìŠ¤(0)(ì •ìƒ) - 900ê°œ\n",
    "- í´ë˜ìŠ¤(1)(ì´ìƒ) - 100ê°œ\n",
    "- ì´ëŸ° ì‹ìœ¼ë¡œ ë°ì´í„°ê°€ í•œìª½ìœ¼ë¡œ ì ë ¤ ìˆëŠ” ê²½ìš°, ëª¨ë¸ì´ ì œëŒ€ë¡œ í•™ìŠµë˜ì§€ ì•Šì•„ìš”. ì™œëƒë©´â€¦\n",
    "- ëª¨ë¸ì´ \"í´ë˜ìŠ¤ 0ë§Œ ì˜ˆì¸¡í•´ë„ ì •í™•ë„ê°€ 90%\"ê°€ ë˜ê¸° ë•Œë¬¸ì´ì—ìš” \n",
    "- í•˜ì§€ë§Œ ì •ì‘ ì¤‘ìš”í•œ ê±´ í´ë˜ìŠ¤ 1(ì´ìƒ)ì„ ì˜ ì¡ì•„ë‚´ëŠ” ê±°ì–ì•„ìš”?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ê·¸ë˜ì„œ ë“±ì¥í•œ ê²Œ SMOTE!\n",
    "- SMOTEëŠ” ì†Œìˆ˜ í´ë˜ìŠ¤ì˜ ë°ì´í„°ë¥¼ ë³µì œí•˜ëŠ” ê²Œ ì•„ë‹ˆë¼\n",
    "- ğŸ‘‰ **ê¸°ì¡´ ì†Œìˆ˜ í´ë˜ìŠ¤ ë°ì´í„°ë¥¼ ë°”íƒ•ìœ¼ë¡œ ë¹„ìŠ·í•˜ì§€ë§Œ ìƒˆë¡œìš´ ë°ì´í„°ë¥¼ \"ìƒì„±\"**í•©ë‹ˆë‹¤.\n",
    "\n",
    "- ğŸ§¬ ì–´ë–»ê²Œ ìƒì„±í•˜ë‚˜ìš”? (ì•„ì£¼ ê°„ë‹¨í•œ ì„¤ëª…)\n",
    "- ì†Œìˆ˜ í´ë˜ìŠ¤ ë°ì´í„° í•˜ë‚˜ë¥¼ ê³ ë¦…ë‹ˆë‹¤.\n",
    "\n",
    "- ê·¸ì™€ ê°€ê¹Œìš´ ë‹¤ë¥¸ ì†Œìˆ˜ í´ë˜ìŠ¤ ë°ì´í„°ë“¤ì„ ì°¾ìŠµë‹ˆë‹¤. (ë³´í†µ K=5 ê¸°ì¤€ìœ¼ë¡œ)\n",
    "\n",
    "- ì´ì›ƒë“¤ê³¼ ì„ ì„ ê·¸ì–´ì„œ ê·¸ ì„  ìœ„ì— ì¤‘ê°„ ì§€ì ì„ ëœë¤í•˜ê²Œ ë½‘ì•„ ìƒˆë¡œìš´ ë°ì´í„°ë¥¼ ìƒì„±í•©ë‹ˆë‹¤.\n",
    "\n",
    "\n",
    "- ì›ë˜ ìˆë˜ ì (â—)ê³¼ ì´ì›ƒ ì‚¬ì´ë¥¼ ì„ ìœ¼ë¡œ ì—°ê²°í•´\n",
    "- ê·¸ ì‚¬ì´ ì–´ë”˜ê°€ì— ìƒˆë¡œìš´ ì (â˜…)ì„ ë§Œë“ ë‹¤ê³  ë³´ë©´ ë¼ìš”!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- ì†Œìˆ˜ í´ë˜ìŠ¤ì˜ ë°ì´í„°ë¥¼ ëŠ˜ë ¤ ë°ì´í„° ë¶ˆê· í˜• ë¬¸ì œ í•´ê²°, ê¸°ì¡´ ì†Œìˆ˜ í´ë˜ìŠ¤ ë°ì´í„°ë¥¼ ê¸°ë°˜ìœ¼ë¡œ ìƒˆë¡œìš´ ë°ì´í„° ìƒì„±, ë°ì´í„° ë³µì œ ëŒ€ì‹  ìƒì„±     â†’ ê³¼ì í•© ì¤„ì´ê³  í•™ìŠµ ì„±ëŠ¥ í–¥ìƒ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting imbalanced-learn\n",
      "  Downloading imbalanced_learn-0.13.0-py3-none-any.whl.metadata (8.8 kB)\n",
      "Requirement already satisfied: numpy<3,>=1.24.3 in c:\\users\\hyuna\\anaconda3\\envs\\pystudy_env\\lib\\site-packages (from imbalanced-learn) (2.2.4)\n",
      "Requirement already satisfied: scipy<2,>=1.10.1 in c:\\users\\hyuna\\anaconda3\\envs\\pystudy_env\\lib\\site-packages (from imbalanced-learn) (1.15.2)\n",
      "Requirement already satisfied: scikit-learn<2,>=1.3.2 in c:\\users\\hyuna\\anaconda3\\envs\\pystudy_env\\lib\\site-packages (from imbalanced-learn) (1.6.1)\n",
      "Collecting sklearn-compat<1,>=0.1 (from imbalanced-learn)\n",
      "  Downloading sklearn_compat-0.1.3-py3-none-any.whl.metadata (18 kB)\n",
      "Requirement already satisfied: joblib<2,>=1.1.1 in c:\\users\\hyuna\\anaconda3\\envs\\pystudy_env\\lib\\site-packages (from imbalanced-learn) (1.4.2)\n",
      "Requirement already satisfied: threadpoolctl<4,>=2.0.0 in c:\\users\\hyuna\\anaconda3\\envs\\pystudy_env\\lib\\site-packages (from imbalanced-learn) (3.6.0)\n",
      "Downloading imbalanced_learn-0.13.0-py3-none-any.whl (238 kB)\n",
      "Downloading sklearn_compat-0.1.3-py3-none-any.whl (18 kB)\n",
      "Installing collected packages: sklearn-compat, imbalanced-learn\n",
      "Successfully installed imbalanced-learn-0.13.0 sklearn-compat-0.1.3\n"
     ]
    }
   ],
   "source": [
    "!pip install imbalanced-learn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### **ğŸ“Œ `imblearn` (imbalanced-learn) íŒ¨í‚¤ì§€**\n",
    "**ì£¼ìš” ê¸°ëŠ¥**\n",
    "1. **ì˜¤ë²„ìƒ˜í”Œë§(Over-sampling)** â†’ ì†Œìˆ˜ í´ë˜ìŠ¤ ë°ì´í„° ìƒ˜í”Œì„ ì¦ê°€ì‹œí‚´  \n",
    "   - `SMOTE` (Synthetic Minority Over-sampling Technique)  \n",
    "   - `ADASYN` (Adaptive Synthetic Sampling)  \n",
    "\n",
    "2. **ì–¸ë”ìƒ˜í”Œë§(Under-sampling)** â†’ ë‹¤ìˆ˜ í´ë˜ìŠ¤ ë°ì´í„° ìƒ˜í”Œì„ ì¤„ì„  \n",
    "   - `RandomUnderSampler`  \n",
    "   - `NearMiss`  \n",
    "\n",
    "3. **ì•™ìƒë¸” ê¸°ë²•(Ensemble Methods)**  \n",
    "   - `BalancedBaggingClassifier` â†’ í´ë˜ìŠ¤ ê· í˜•ì„ ìœ ì§€í•˜ë©° ë°°ê¹… ì ìš©  \n",
    "   - `BalancedRandomForestClassifier` â†’ ë¶ˆê· í˜• ë°ì´í„°ì— ìµœì í™”ëœ ëœë¤ í¬ë ˆìŠ¤íŠ¸  \n",
    "\n",
    "4. **SMOTE ë³€í˜• ê¸°ë²•**  \n",
    "   - `BorderlineSMOTE` â†’ ê²½ê³„ì„  ìƒ˜í”Œë§Œ ì¦ê°•  \n",
    "   - `SMOTENC` â†’ ë²”ì£¼í˜• ë°ì´í„°ë¥¼ í¬í•¨í•œ SMOTE "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- ì–¸ë”ìƒ˜í”Œë§ì€ ë‹¤ìˆ˜ í´ë˜ìŠ¤(ë„ˆë¬´ ë§ì€ í´ë˜ìŠ¤)ì˜ ë°ì´í„°ë¥¼ ì¼ë¶€ë§Œ ë‚¨ê¸°ê³  ë²„ë¦¬ëŠ” ë°©ë²•. \n",
    "- ë‹¤ìˆ˜ í´ë˜ìŠ¤ ë°ì´í„°ê°€ ë„ˆë¬´ ë§ì„ ë•Œ (ëª¨ë¸ì´ ë„ˆë¬´ ë§ì€ ì •ìƒ ë°ì´í„°ë¥¼ í•™ìŠµí•˜ë©´, **ì†Œìˆ˜ í´ë˜ìŠ¤(ì˜ˆ: ì´ìƒ íƒì§€)**ë¥¼ ë¬´ì‹œí•  ìˆ˜ ìˆìŒ.)\n",
    "- ë°ì´í„° ì „ì²´ëŸ‰ì´ ë„ˆë¬´ ì»¤ì„œ í•™ìŠµ ì‹œê°„ì´ ì˜¤ë˜ ê±¸ë¦´ ë•Œ (ì¼ë¶€ë§Œ ì¨ë„ ì¶©ë¶„íˆ íŒ¨í„´ì„ ë°°ìš¸ ìˆ˜ ìˆë‹¤ë©´ íš¨ìœ¨ì !)\n",
    "- ì†Œìˆ˜ í´ë˜ìŠ¤ ë°ì´í„°ë¥¼ ëŠ˜ë¦¬ê¸° ì–´ë ¤ìš¸ ë•Œ (SMOTEë¡œ ìƒˆë¡œìš´ ë°ì´í„°ë¥¼ ë§Œë“¤ê¸° í˜ë“  ìƒí™©ì—ì„œ ì°¨ì„ ì±…ìœ¼ë¡œ ì‚¬ìš©.)\n",
    "\n",
    "- ì–¸ë”ìƒ˜í”Œë§ í• ë•Œ ì£¼ì˜í•  ì ì€, ë°ì´í„°ë¥¼ ì¤„ì´ê¸° ë•Œë¬¸ì— ì¤‘ìš”í•œ ì •ë³´ê°€ ì†ì‹¤ë  ìˆ˜ ìˆì–´ìš”. â†’ ê·¸ë˜ì„œ ë„ˆë¬´ ê³¼í•˜ê²Œ ì¤„ì´ë©´ ëª¨ë¸ ì„±ëŠ¥ì´ ì˜¤íˆë ¤ ë‚˜ë¹ ì§ˆ ìˆ˜ ìˆì–´ìš”."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- ë‘ê°œ ì„ì–´ì„œ ì“°ëŠ” ë°©ë²•ë„ ìˆìŒ\n",
    "- ì†Œìˆ˜ í´ë˜ìŠ¤ëŠ” ì˜¤ë²„ìƒ˜í”Œë§, ë‹¤ìˆ˜ í´ë˜ìŠ¤ëŠ” ì•½ê°„ë§Œ ì–¸ë”ìƒ˜í”Œë§ í•´ì„œ ê· í˜•ë„ ë§ì¶”ê³ , ì„±ëŠ¥ë„ ì±™ê¸°ëŠ” ì „ëµ.\n",
    "\n",
    "- from imblearn.combine import SMOTEENN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Before SMOTE: [897 103]\n",
      "After SMOTE: [897 897]\n",
      "(1000, 20) (1000,)\n",
      "(1794, 20) (1794,)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\hyuna\\anaconda3\\envs\\pystudy_env\\Lib\\site-packages\\joblib\\externals\\loky\\backend\\context.py:136: UserWarning: Could not find the number of physical cores for the following reason:\n",
      "[WinError 2] ì§€ì •ëœ íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤\n",
      "Returning the number of logical cores instead. You can silence this warning by setting LOKY_MAX_CPU_COUNT to the number of cores you want to use.\n",
      "  warnings.warn(\n",
      "  File \"c:\\Users\\hyuna\\anaconda3\\envs\\pystudy_env\\Lib\\site-packages\\joblib\\externals\\loky\\backend\\context.py\", line 257, in _count_physical_cores\n",
      "    cpu_info = subprocess.run(\n",
      "               ^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\hyuna\\anaconda3\\envs\\pystudy_env\\Lib\\subprocess.py\", line 550, in run\n",
      "    with Popen(*popenargs, **kwargs) as process:\n",
      "         ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\hyuna\\anaconda3\\envs\\pystudy_env\\Lib\\subprocess.py\", line 1028, in __init__\n",
      "    self._execute_child(args, executable, preexec_fn, close_fds,\n",
      "  File \"c:\\Users\\hyuna\\anaconda3\\envs\\pystudy_env\\Lib\\subprocess.py\", line 1540, in _execute_child\n",
      "    hp, ht, pid, tid = _winapi.CreateProcess(executable, args,\n",
      "                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n"
     ]
    }
   ],
   "source": [
    "# SMOTEë¥¼ ì´ìš©í•´ì„œ ë¶ˆê· í˜•í•œ ë°ì´í„°ì…‹ì„ ê· í˜• ìˆê²Œ ë°”ê¾¸ëŠ” ê³¼ì •\n",
    "import numpy as np\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from sklearn.datasets import make_classification\n",
    "\n",
    "X, y = make_classification( # make_classification: ë¨¸ì‹ ëŸ¬ë‹ í…ŒìŠ¤íŠ¸ìš© ë°ì´í„°ë¥¼ ë§Œë“¤ì–´ì£¼ëŠ” í•¨ìˆ˜\n",
    "    n_classes=2, # ë‘ ê°œì˜ í´ë˜ìŠ¤ë¡œ ë¶„ë¥˜ (ì˜ˆ: ì •ìƒ/ì´ìƒ)\n",
    "    weights=[0.9, 0.1], # í´ë˜ìŠ¤ 0: 90%, í´ë˜ìŠ¤ 1: 10% \n",
    "    n_samples=1000, # ì´ 1000ê°œ ìƒ˜í”Œ ìƒì„±\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "print(f\"Before SMOTE: {np.bincount(y)}\") # np.bincount(y)ëŠ” í´ë˜ìŠ¤ë³„ ìƒ˜í”Œ ê°œìˆ˜ë¥¼ ì„¸ì–´ì¤˜ìš”\n",
    "\n",
    "smote = SMOTE(random_state=42) # SMOTE()ë¥¼ ì‚¬ìš©í•´ì„œ ì†Œìˆ˜ í´ë˜ìŠ¤(í´ë˜ìŠ¤ 1)ì˜ ë°ì´í„°ë¥¼ ì¸ê³µì ìœ¼ë¡œ \"ìƒì„±\"\n",
    "X_resample, y_resample = smote.fit_resample(X, y) # it_resample(X, y)ë¥¼ í†µí•´ ìƒˆë¡œìš´ balanced ë°ì´í„°ì…‹ì„ ì–»ì–´ìš”\n",
    "\n",
    "print(f\"After SMOTE: {np.bincount(y_resample)}\")\n",
    "print(X.shape, y.shape)\n",
    "print(X_resample.shape, y_resample.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.98      0.98       179\n",
      "           1       0.85      0.81      0.83        21\n",
      "\n",
      "    accuracy                           0.96       200\n",
      "   macro avg       0.91      0.90      0.90       200\n",
      "weighted avg       0.96      0.96      0.96       200\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "X_train, X_test, y_train, y_test = \\\n",
    "    train_test_split(X, y, test_size=0.2, stratify=y) \n",
    "# test_size=0.2: í…ŒìŠ¤íŠ¸ ë°ì´í„°ëŠ” ì „ì²´ì˜ 20%, stratify=y: í´ë˜ìŠ¤ ë¹„ìœ¨ì´ í•™ìŠµ/í…ŒìŠ¤íŠ¸ì— ë™ì¼í•˜ê²Œ ìœ ì§€ë˜ë„ë¡ í•¨ (ë¶ˆê· í˜• ë°ì´í„°ì¼ ë•Œ ì¤‘ìš”!)\n",
    "\n",
    "model = RandomForestClassifier(random_state=0) # RandomForestClassifier: ì—¬ëŸ¬ ê°œì˜ ê²°ì • íŠ¸ë¦¬ë¥¼ ì¡°í•©í•œ ì•™ìƒë¸” ëª¨ë¸ \n",
    "model.fit(X_train, y_train) # .fit(): í•™ìŠµ ë°ì´í„°ë¥¼ ì´ìš©í•´ ëª¨ë¸ í›ˆë ¨\n",
    "\n",
    "y_pred = model.predict(X_test)\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Precision ì€ ë‚´ê°€ 1ì´ë¼ê³  ì˜ˆì¸¡í•œ ê²ƒ ì¤‘ì— ì§„ì§œ 1ì¸ ë¹„ìœ¨\n",
    "- recall ì€ ì‹¤ì œ 1 ì¤‘ì—ì„œ ë‚´ê°€ ë§ì¶˜ ë¹„ìœ¨\n",
    "- f1-score ëŠ” precisionê³¼ recallì˜ ê· í˜•\n",
    "- support ëŠ” ê° í´ë˜ìŠ¤ì˜ ìƒ˜í”Œ ìˆ˜\n",
    "- accuracy ëŠ” ì „ì²´ ìƒ˜í”Œ ì¤‘ ë§ì¶˜ ë¹„ìœ¨\n",
    "- marco avg ëŠ” í´ë˜ìŠ¤ë§ˆë‹¤ ê³„ì‚°í•œ í‰ê·  (ëª¨ë“  í´ë˜ìŠ¤ ë™ë“±í•˜ê²Œ ë°˜ì˜)\n",
    "- weighted avg í´ë˜ìŠ¤ ê°œìˆ˜ ë¹„ìœ¨ì„ ê°€ì¤‘ì¹˜ë¡œ ë°˜ì˜í•œ í‰ê· \n",
    "\n",
    "- ğŸ¯ F1-scoreê°€ í•„ìš”í•œ ì´ìœ ?\n",
    "- Precisionì´ ë†’ì•„ë„ Recallì´ ë‚®ìœ¼ë©´? â†’ ë†“ì¹˜ëŠ” ì¼€ì´ìŠ¤ ë§ìŒ\n",
    "\n",
    "- Recallì´ ë†’ì•„ë„ Precisionì´ ë‚®ìœ¼ë©´? â†’ ì˜ëª»ëœ ê²½ê³ ê°€ ë§ìŒ\n",
    "- â¡ï¸ ì´ëŸ´ ë•Œ, ë‘ ê°’ì„ ì ì ˆíˆ ê· í˜• ìˆê²Œ í‰ê°€í•˜ëŠ” ê²Œ F1-score!\n",
    "- ğŸ§  ì™œ **ì¡°í™” í‰ê· (Harmonic Mean)**ì„ ì“°ë‚˜ìš”?\n",
    "- ë‹¨ìˆœ í‰ê· (mean)ì€ í° ê°’ì´ ì‘ìŒì„ ë³´ì™„í•´ë²„ë¦¬ì§€ë§Œ,\n",
    "\n",
    "- ì¡°í™” í‰ê· ì€ ì‘ì€ ê°’ì— ë” ë¯¼ê°í•´ì„œ,\n",
    "- Precisionì´ë‚˜ Recall ë‘˜ ì¤‘ í•˜ë‚˜ë¼ë„ ë‚®ìœ¼ë©´ F1ë„ ë‚®ê²Œ ë‚˜ì™€ìš”!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.95      0.96       181\n",
      "           1       0.95      0.98      0.96       178\n",
      "\n",
      "    accuracy                           0.96       359\n",
      "   macro avg       0.96      0.96      0.96       359\n",
      "weighted avg       0.96      0.96      0.96       359\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# \"SMOTEë¡œ ëŠ˜ë¦° ë°ì´í„°(X_resample, y_resample)ë¥¼ í›ˆë ¨/í…ŒìŠ¤íŠ¸ìš©ìœ¼ë¡œ ë‚˜ëˆˆ ë‹¤ìŒ,\n",
    "# ëœë¤ í¬ë ˆìŠ¤íŠ¸ë¡œ í•™ìŠµ â†’ ì˜ˆì¸¡ â†’ ì„±ëŠ¥ í‰ê°€(classification_report)ê¹Œì§€ ì­‰ ì‹¤í–‰í•˜ëŠ” ì½”ë“œ\"\n",
    "\n",
    "X_train, X_test, y_train, y_test = \\\n",
    "    train_test_split(X_resample, y_resample, test_size=0.2) #X_resample, y_resample: SMOTEë¡œ í´ë˜ìŠ¤ ê· í˜•ì„ ë§ì¶˜ ë°ì´í„°\n",
    "\n",
    "model = RandomForestClassifier(random_state=0)\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "y_pred = model.predict(X_test)\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- ì½”ë“œì—ì„œ \\ ëŠ” ì½”ë“œê°„ì˜ ë„ì–´ì“°ê¸° ìš©ë„"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pystudy_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
